{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NexusML Enhanced Modular Notebook Template\n",
    "\n",
    "This enhanced template demonstrates how to use the notebook_utils module to create a more modular and maintainable notebook for NexusML experiments. It includes improved error handling, better documentation, and a more streamlined workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's initialize the notebook environment to ensure proper imports and path configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the notebook environment\n",
    "# This ensures that the nexusml package can be imported correctly\n",
    "%run init_notebook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import notebook utilities\n",
    "from nexusml.utils.notebook_utils import (\n",
    "    setup_notebook_environment,\n",
    "    discover_and_load_data,\n",
    "    explore_data,\n",
    "    setup_pipeline_components,\n",
    "    visualize_metrics,\n",
    "    visualize_confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the notebook environment with common configurations\n",
    "paths = setup_notebook_environment()\n",
    "\n",
    "# Display available paths\n",
    "print(\"Project paths:\")\n",
    "for name, path in paths.items():\n",
    "    print(f\"  {name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Setup\n",
    "\n",
    "Set up the configuration for our experiment. This ensures that NexusML has access to the correct configuration settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the NEXUSML_CONFIG environment variable to point to the absolute path of the configuration file\n",
    "project_root = paths[\"project_root\"]\n",
    "config_file_path = os.path.abspath(os.path.join(project_root, 'nexusml/config/nexusml_config.yml'))\n",
    "os.environ['NEXUSML_CONFIG'] = config_file_path\n",
    "print(f\"Setting NEXUSML_CONFIG to: {config_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the configuration provider with error handling\n",
    "try:\n",
    "    from nexusml.core.config.provider import ConfigurationProvider\n",
    "    config_provider = ConfigurationProvider()\n",
    "    config = config_provider.config\n",
    "    \n",
    "    print(f\"Configuration loaded successfully\")\n",
    "    \n",
    "    # Display key configuration sections\n",
    "    if hasattr(config, 'feature_engineering'):\n",
    "        print(f\"Feature Engineering Configuration: {len(config.feature_engineering.text_combinations)} text combinations, \"\n",
    "              f\"{len(config.feature_engineering.numeric_columns)} numeric columns\")\n",
    "    \n",
    "    if hasattr(config, 'classification'):\n",
    "        print(f\"Classification Configuration: {len(config.classification.classification_targets)} classification targets\")\n",
    "    \n",
    "    if hasattr(config, 'data'):\n",
    "        print(f\"Data Configuration: {len(config.data.required_columns)} required columns\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading configuration: {e}\")\n",
    "    print(\"Creating default configuration...\")\n",
    "    \n",
    "    from nexusml.core.config.configuration import NexusMLConfig\n",
    "    config = NexusMLConfig()\n",
    "    config_provider.set_config(config)\n",
    "    \n",
    "    print(\"Default configuration created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Exploration\n",
    "\n",
    "Now, let's load the data and explore it using the modular utilities. This section demonstrates how to discover available data files, load them, and perform basic exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover and load data\n",
    "try:\n",
    "    # The discover_and_load_data function will automatically find available data files\n",
    "    # and load the specified one (or the first one if none is specified)\n",
    "    data, data_path = discover_and_load_data()\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nFirst few rows of the data:\")\n",
    "    display(data.head())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please ensure that data files are available in the expected locations.\")\n",
    "    print(\"You can specify custom search paths using the search_paths parameter.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "try:\n",
    "    # The explore_data function provides basic statistics and information about the data\n",
    "    exploration_results = explore_data(data)\n",
    "    \n",
    "    # Additional custom exploration\n",
    "    print(\"\\nUnique values in categorical columns:\")\n",
    "    for col in data.select_dtypes(include=['object']).columns:\n",
    "        print(f\"  {col}: {data[col].nunique()} unique values\")\n",
    "        \n",
    "except NameError:\n",
    "    print(\"Data not loaded. Please load data first.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error exploring data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Setup\n",
    "\n",
    "Let's set up the pipeline components for our experiment. This section demonstrates how to create and configure the NexusML pipeline components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline components\n",
    "try:\n",
    "    # The setup_pipeline_components function creates and configures all necessary pipeline components\n",
    "    pipeline_components = setup_pipeline_components()\n",
    "    \n",
    "    # Extract components for easier access\n",
    "    registry = pipeline_components[\"registry\"]\n",
    "    container = pipeline_components[\"container\"]\n",
    "    factory = pipeline_components[\"factory\"]\n",
    "    context = pipeline_components[\"context\"]\n",
    "    orchestrator = pipeline_components[\"orchestrator\"]\n",
    "    \n",
    "    print(\"Pipeline components set up successfully\")\n",
    "    \n",
    "    # Display registered components\n",
    "    print(\"\\nRegistered components:\")\n",
    "    for interface, implementations in registry._registry.items():\n",
    "        interface_name = interface.__name__\n",
    "        print(f\"  {interface_name}:\")\n",
    "        for name, impl in implementations.items():\n",
    "            print(f\"    - {name}: {impl.__name__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error setting up pipeline components: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "Now, let's train a model using the pipeline. This section demonstrates how to use the orchestrator to train a model with the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model\n",
    "try:\n",
    "    # Define the output directory for the model\n",
    "    output_dir = os.path.join(paths[\"project_root\"], \"outputs\", \"models\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Train the model using the orchestrator\n",
    "    model, metrics = orchestrator.train_model(\n",
    "        data_path=data_path,\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        optimize_hyperparameters=True,\n",
    "        output_dir=output_dir,\n",
    "        model_name=\"equipment_classifier_enhanced\",\n",
    "    )\n",
    "    \n",
    "    print(\"Model training completed successfully\")\n",
    "    print(f\"Model saved to: {orchestrator.context.get('model_path')}\")\n",
    "    print(f\"Metadata saved to: {orchestrator.context.get('metadata_path')}\")\n",
    "    \n",
    "    print(\"\\nMetrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error training model: {e}\")\n",
    "    print(\"\\nTroubleshooting tips:\")\n",
    "    print(\"1. Check that the data contains the expected columns\")\n",
    "    print(\"2. Verify that the configuration is set up correctly\")\n",
    "    print(\"3. Ensure that all required dependencies are installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Let's evaluate the model in more detail. This section demonstrates how to use the orchestrator to evaluate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "try:\n",
    "    # Define the output path for evaluation results\n",
    "    evaluation_output_path = os.path.join(paths[\"project_root\"], \"outputs\", \"evaluation_results_enhanced.json\")\n",
    "    \n",
    "    # Evaluate the model using the orchestrator\n",
    "    results = orchestrator.evaluate(\n",
    "        model=model,\n",
    "        data_path=data_path,\n",
    "        output_path=evaluation_output_path,\n",
    "    )\n",
    "    \n",
    "    print(\"Evaluation completed successfully\")\n",
    "    print(f\"Evaluation results saved to: {evaluation_output_path}\")\n",
    "    \n",
    "    print(\"\\nMetrics:\")\n",
    "    for key, value in results[\"metrics\"].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "except NameError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Model not trained. Please train the model first.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error evaluating model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization\n",
    "\n",
    "Let's visualize the results using the modular visualization utilities. This section demonstrates how to create visualizations of the model metrics and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the metrics\n",
    "try:\n",
    "    # Visualize metrics using the utility function\n",
    "    visualize_metrics(metrics)\n",
    "    \n",
    "    # Create a confusion matrix if available\n",
    "    if 'confusion_matrix' in results['analysis']:\n",
    "        cm = results['analysis']['confusion_matrix']\n",
    "        visualize_confusion_matrix(cm)\n",
    "    \n",
    "except NameError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Metrics or results not available. Please train and evaluate the model first.\")\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(f\"Error: {e} not found in results\")\n",
    "    print(\"The confusion matrix may not be available in the results.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error visualizing results: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance\n",
    "\n",
    "Let's examine the feature importance to understand which features are most influential in the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "try:\n",
    "    # Check if the model has feature_importances_ attribute (e.g., for tree-based models)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Get feature names from the model's metadata if available\n",
    "        feature_names = orchestrator.context.get('feature_names', None)\n",
    "        \n",
    "        if feature_names is None:\n",
    "            print(\"Feature names not found in context. Using generic feature names.\")\n",
    "            feature_names = [f\"Feature {i}\" for i in range(len(model.feature_importances_))]\n",
    "        \n",
    "        # Create a DataFrame for visualization\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': model.feature_importances_\n",
    "        })\n",
    "        \n",
    "        # Sort by importance\n",
    "        importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "        \n",
    "        # Display the top features\n",
    "        print(\"Top 10 most important features:\")\n",
    "        display(importance_df.head(10))\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "        plt.title('Feature Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"This model type doesn't provide feature importance information.\")\n",
    "        \n",
    "except NameError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Model not trained. Please train the model first.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error visualizing feature importance: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prediction\n",
    "\n",
    "Finally, let's make predictions on new data. This section demonstrates how to use the trained model to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for prediction\n",
    "try:\n",
    "    # Create a sample DataFrame with the same structure as the training data\n",
    "    prediction_data = pd.DataFrame({\n",
    "        \"equipment_tag\": [\"AHU-01\", \"CHW-01\", \"P-01\"],\n",
    "        \"manufacturer\": [\"Trane\", \"Carrier\", \"Armstrong\"],\n",
    "        \"model\": [\"M-1000\", \"C-2000\", \"A-3000\"],\n",
    "        \"description\": [\n",
    "            \"Air Handling Unit with cooling coil\",\n",
    "            \"Centrifugal Chiller for HVAC system\",\n",
    "            \"Centrifugal Pump for chilled water\",\n",
    "        ],\n",
    "    })\n",
    "    \n",
    "    print(\"Sample prediction data:\")\n",
    "    display(prediction_data)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating sample data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "try:\n",
    "    # Define the output path for predictions\n",
    "    prediction_output_path = os.path.join(paths[\"project_root\"], \"outputs\", \"predictions_enhanced.csv\")\n",
    "    \n",
    "    # Make predictions using the orchestrator\n",
    "    predictions = orchestrator.predict(\n",
    "        model=model,\n",
    "        data=prediction_data,\n",
    "        output_path=prediction_output_path,\n",
    "    )\n",
    "    \n",
    "    print(\"Predictions completed successfully\")\n",
    "    print(f\"Predictions saved to: {prediction_output_path}\")\n",
    "    \n",
    "    print(\"\\nSample predictions:\")\n",
    "    display(predictions)\n",
    "    \n",
    "except NameError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Model not trained or prediction data not created. Please complete the previous steps first.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error making predictions: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to use the NexusML package for equipment classification using an enhanced modular approach. We loaded data, trained a model, evaluated it, and made predictions using the new architecture and modular utilities.\n",
    "\n",
    "The enhanced modular approach provides several benefits:\n",
    "\n",
    "1. Better code organization and reusability\n",
    "2. Improved error handling and troubleshooting\n",
    "3. Consistent visualization and reporting\n",
    "4. Simplified data discovery and loading\n",
    "5. Additional analysis capabilities like feature importance\n",
    "\n",
    "This template can be used as a starting point for your own NexusML experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Next Steps\n",
    "\n",
    "Here are some potential next steps for further exploration:\n",
    "\n",
    "1. Try different model types and hyperparameters\n",
    "2. Experiment with different feature engineering techniques\n",
    "3. Perform cross-validation for more robust evaluation\n",
    "4. Deploy the model for production use\n",
    "5. Create a custom pipeline component for specific needs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}