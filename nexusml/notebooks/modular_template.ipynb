{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NexusML Modular Notebook Template\n",
        "\n",
        "This template demonstrates how to use the notebook_utils module to create a more modular and maintainable notebook for NexusML experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Add the project root to the Python path if needed\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "\n",
        "# Import the notebook utilities\n",
        "from nexusml.utils.notebook_utils import (\n",
        "    setup_notebook_environment,\n",
        "    discover_and_load_data,\n",
        "    explore_data,\n",
        "    setup_pipeline_components,\n",
        "    visualize_metrics,\n",
        "    visualize_confusion_matrix\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Environment\n",
        "\n",
        "First, let's set up the notebook environment with common configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up the notebook environment\n",
        "paths = setup_notebook_environment()\n",
        "print(\"Project paths:\")\n",
        "for name, path in paths.items():\n",
        "    print(f\"  {name}: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set up the configuration for our experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the NEXUSML_CONFIG environment variable to point to the absolute path of the configuration file\n",
        "config_file_path = os.path.abspath(os.path.join(project_root, 'nexusml/config/nexusml_config.yml'))\n",
        "os.environ['NEXUSML_CONFIG'] = config_file_path\n",
        "print(f\"Setting NEXUSML_CONFIG to: {config_file_path}\")\n",
        "\n",
        "# Get the configuration provider\n",
        "from nexusml.core.config.provider import ConfigurationProvider\n",
        "config_provider = ConfigurationProvider()\n",
        "\n",
        "# Get the configuration with error handling\n",
        "try:\n",
        "    config = config_provider.config\n",
        "    print(f\"Configuration loaded successfully\")\n",
        "    print(f\"Feature Engineering Configuration: {len(config.feature_engineering.text_combinations)} text combinations, {len(config.feature_engineering.numeric_columns)} numeric columns\")\n",
        "    print(f\"Classification Configuration: {len(config.classification.classification_targets)} classification targets\")\n",
        "    print(f\"Data Configuration: {len(config.data.required_columns)} required columns\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading configuration: {e}\")\n",
        "    print(\"Creating default configuration...\")\n",
        "    from nexusml.core.config.configuration import NexusMLConfig\n",
        "    config = NexusMLConfig()\n",
        "    config_provider.set_config(config)\n",
        "    print(\"Default configuration created successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading and Exploration\n",
        "\n",
        "Now, let's load the data and explore it using the modular utilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Discover and load data\n",
        "data, data_path = discover_and_load_data()\n",
        "\n",
        "# Display the first few rows\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore the data\n",
        "exploration_results = explore_data(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline Setup\n",
        "\n",
        "Let's set up the pipeline components for our experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up pipeline components\n",
        "pipeline_components = setup_pipeline_components()\n",
        "\n",
        "# Extract components for easier access\n",
        "registry = pipeline_components[\"registry\"]\n",
        "container = pipeline_components[\"container\"]\n",
        "factory = pipeline_components[\"factory\"]\n",
        "context = pipeline_components[\"context\"]\n",
        "orchestrator = pipeline_components[\"orchestrator\"]\n",
        "\n",
        "print(\"Pipeline components set up successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training\n",
        "\n",
        "Now, let's train a model using the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a model\n",
        "try:\n",
        "    model, metrics = orchestrator.train_model(\n",
        "        data_path=data_path,\n",
        "        test_size=0.3,\n",
        "        random_state=42,\n",
        "        optimize_hyperparameters=True,\n",
        "        output_dir=\"../outputs/models\",\n",
        "        model_name=\"equipment_classifier_modular\",\n",
        "    )\n",
        "    \n",
        "    print(\"Model training completed successfully\")\n",
        "    print(f\"Model saved to: {orchestrator.context.get('model_path')}\")\n",
        "    print(f\"Metadata saved to: {orchestrator.context.get('metadata_path')}\")\n",
        "    print(\"Metrics:\")\n",
        "    for key, value in metrics.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error training model: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation\n",
        "\n",
        "Let's evaluate the model in more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "try:\n",
        "    results = orchestrator.evaluate(\n",
        "        model=model,\n",
        "        data_path=data_path,\n",
        "        output_path=\"../outputs/evaluation_results_modular.json\",\n",
        "    )\n",
        "    \n",
        "    print(\"Evaluation completed successfully\")\n",
        "    print(f\"Evaluation results saved to: ../outputs/evaluation_results_modular.json\")\n",
        "    print(\"Metrics:\")\n",
        "    for key, value in results[\"metrics\"].items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error evaluating model: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization\n",
        "\n",
        "Let's visualize the results using the modular visualization utilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the metrics\n",
        "try:\n",
        "    # Visualize metrics using the utility function\n",
        "    visualize_metrics(metrics)\n",
        "    \n",
        "    # Create a confusion matrix if available\n",
        "    if 'confusion_matrix' in results['analysis']:\n",
        "        cm = results['analysis']['confusion_matrix']\n",
        "        visualize_confusion_matrix(cm)\n",
        "except Exception as e:\n",
        "    print(f\"Error visualizing results: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction\n",
        "\n",
        "Finally, let's make predictions on new data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample data for prediction\n",
        "prediction_data = pd.DataFrame({\n",
        "    \"equipment_tag\": [\"AHU-01\", \"CHW-01\", \"P-01\"],\n",
        "    \"manufacturer\": [\"Trane\", \"Carrier\", \"Armstrong\"],\n",
        "    \"model\": [\"M-1000\", \"C-2000\", \"A-3000\"],\n",
        "    \"description\": [\n",
        "        \"Air Handling Unit with cooling coil\",\n",
        "        \"Centrifugal Chiller for HVAC system\",\n",
        "        \"Centrifugal Pump for chilled water\",\n",
        "    ],\n",
        "})\n",
        "\n",
        "# Make predictions\n",
        "try:\n",
        "    predictions = orchestrator.predict(\n",
        "        model=model,\n",
        "        data=prediction_data,\n",
        "        output_path=\"../outputs/predictions_modular.csv\",\n",
        "    )\n",
        "    \n",
        "    print(\"Predictions completed successfully\")\n",
        "    print(f\"Predictions saved to: {orchestrator.context.get('output_path')}\")\n",
        "    print(\"Sample predictions:\")\n",
        "    display(predictions)\n",
        "except Exception as e:\n",
        "    print(f\"Error making predictions: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we demonstrated how to use the NexusML package for equipment classification using a modular approach. We loaded data, trained a model, evaluated it, and made predictions using the new architecture and modular utilities.\n",
        "\n",
        "The modular approach provides several benefits:\n",
        "1. Better code organization and reusability\n",
        "2. Improved maintainability\n",
        "3. Consistent error handling\n",
        "4. Simplified data discovery and loading\n",
        "5. Standardized visualization"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
